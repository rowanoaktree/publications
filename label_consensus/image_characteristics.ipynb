{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of image factors on annotation consensus within observer groups\n",
    "\n",
    "Analytic code supporting \"Observer variability in manual-visual interpretation of aerial imagery of wildlife, with implications for deep learning\" - Converse et al. submitted Feb 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis annotations\n",
    "path = \"path/to/labels.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "\n",
    "#Derive dependent variables for image factors analysis: fraction of guesses that agree with consensus\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store counts of class_orig for each group\n",
    "class_counts_dict = {}\n",
    "\n",
    "# Group the dataframe by image, then by cluster\n",
    "grouped = df.groupby(['filename', 'cluster_id'])\n",
    "\n",
    "# Create empty lists to store the results\n",
    "cluster_id_list = []\n",
    "filename_list = []\n",
    "consensus_class_id_list = []\n",
    "consensus_bbox_list = []\n",
    "consensus_guess_list = []\n",
    "num_annotations_list = []\n",
    "correct_guess_list = []\n",
    "\n",
    "# Loop through each group and calculate Pielou's evenness index\n",
    "for name, group in grouped:\n",
    "    # Get the cluster ID, filename, and consensus class ID for this group\n",
    "    cluster_id = name[1]\n",
    "    filename = name[0]\n",
    "    consensus_class_id = group['cat_refined'].iloc[0]  # Assumes all consensus IDs in the group are the same\n",
    "    consensus_bbox = group['bbox_refined'].iloc[0]\n",
    "\n",
    "    # Count the number of annotations in the group\n",
    "    num_annotations = len(group)\n",
    "\n",
    "    # Create a list of class_orig values for this group\n",
    "    class_orig_values = group['cat_orig'].tolist()\n",
    "\n",
    "    # Count the number of times each class_orig appears in this group\n",
    "    class_counts = pd.Series(class_orig_values).value_counts()\n",
    "\n",
    "    # Count the number of times the consensus class appears\n",
    "    consensus_count = class_counts.get(consensus_class_id, 0)\n",
    "\n",
    "    # Calculate the proportion of correct guesses\n",
    "    proportion_correct = consensus_count / num_annotations\n",
    "\n",
    "    # Append the results to the lists\n",
    "    cluster_id_list.append(cluster_id)\n",
    "    filename_list.append(filename)\n",
    "    consensus_class_id_list.append(consensus_class_id)\n",
    "    consensus_bbox_list.append(consensus_bbox)\n",
    "    num_annotations_list.append(num_annotations)\n",
    "    consensus_guess_list.append(consensus_count)\n",
    "    correct_guess_list.append(proportion_correct)\n",
    "\n",
    "# Create a new dataframe with the results\n",
    "df = pd.DataFrame({\n",
    "    'cluster_id': cluster_id_list,\n",
    "    'filename': filename_list,\n",
    "    'consensus_class_ID': consensus_class_id_list,\n",
    "    'consensus_bbox': consensus_bbox_list,\n",
    "    'num_annotations': num_annotations_list,\n",
    "    'consensus_guesses': consensus_guess_list,\n",
    "    'correct_fraction': correct_guess_list\n",
    "})\n",
    "\n",
    "#Calculate dependent variable\n",
    "df['n-k'] = df['num_annotations'] - df['consensus_guesses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVE IMAGE/ANNOTATION COVARIATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBOX AREA\n",
    "#Size of the bounding box in pixels\n",
    "\n",
    "def calc_area(row):\n",
    "    bbox = row['consensus_bbox']\n",
    "    xmin, ymin, w, h = bbox\n",
    "    return w * h\n",
    "\n",
    "df['area'] = df.apply(calc_area, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % AREA BBOX\n",
    "# Percent area of the bounding box of the total image area\n",
    "\n",
    "# Define a function to calculate percentage area\n",
    "def calculate_percentage_area(image_filename, bbox_area):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\zooniverse\", image_filename)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None  # You can return a special value, such as None, to indicate the image wasn't found\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    image_area = image_width * image_height\n",
    "\n",
    "    percentage_area = (bbox_area / image_area) * 100\n",
    "    return percentage_area\n",
    "\n",
    "# Calculate and add as a column\n",
    "df['bbox_percent_area'] = df.apply(lambda row: calculate_percentage_area(row['filename'], row['area']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME CLASS %\n",
    "# % of targets of the same class as the analysis target (in the same image)\n",
    "\n",
    "# Define a function to calculate the percentage of same-class neighbors for a given row\n",
    "def calculate_same_class_percentage(row, df):\n",
    "    # Get the filename and class ID of the target bounding box\n",
    "    filename = row['filename']\n",
    "    class_id = row['consensus_class_ID']\n",
    "    \n",
    "    # Filter the DataFrame to include only rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == filename]\n",
    "    \n",
    "    # Calculate the total number of neighbors in the same image\n",
    "    total_neighbors = len(matching_rows) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    if total_neighbors == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    \n",
    "    # Calculate the number of same-class neighbors\n",
    "    same_class_neighbors = len(matching_rows[matching_rows['consensus_class_ID'] == class_id]) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    # Calculate the percentage of same-class neighbors\n",
    "    same_class_percentage = (same_class_neighbors / total_neighbors) * 100\n",
    "    \n",
    "    return same_class_percentage\n",
    "\n",
    "# Calculate the same-class percentage for each row and add the results as a new column\n",
    "df['same_class_percent'] = df.apply(lambda row: calculate_same_class_percentage(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER OF NEIGHBORS \n",
    "# Number of annotations within 2x maximum of bbox width or height (to account for positional differences)\n",
    "\n",
    "# Define a function to calculate the number of neighbors for a given row\n",
    "def count_neighbors(row, df):\n",
    "    # Extract 'bbox' values from the 'consensus_bbox' column as a list [xmin, ymin, width, height]\n",
    "    bbox = row['consensus_bbox']  # Use ast.literal_eval() to safely evaluate the string\n",
    "    \n",
    "    # Define the search radius as 2 times the maximum of width and height\n",
    "    search_radius = 2 * max(bbox[2], bbox[3])\n",
    "    \n",
    "    # Calculate the center coordinates of the bounding box\n",
    "    x_center = bbox[0] + bbox[2] / 2\n",
    "    y_center = bbox[1] + bbox[3] / 2\n",
    "    \n",
    "    # Initialize a count for neighbors\n",
    "    num_neighbors = 0\n",
    "    \n",
    "    # Iterate through rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == row['filename']]\n",
    "    \n",
    "    for _, neighbor_row in matching_rows.iterrows():\n",
    "        if neighbor_row.name != row.name:\n",
    "            # Extract 'bbox' values for the neighbor as a list [xmin, ymin, width, height]\n",
    "            neighbor_bbox = neighbor_row['consensus_bbox']\n",
    "            \n",
    "            # Calculate the center coordinates of the potential neighbor\n",
    "            neighbor_x_center = neighbor_bbox[0] + neighbor_bbox[2] / 2\n",
    "            neighbor_y_center = neighbor_bbox[1] + neighbor_bbox[3] / 2\n",
    "            \n",
    "            # Calculate the Euclidean distance between centers\n",
    "            distance = np.sqrt((x_center - neighbor_x_center)**2 + (y_center - neighbor_y_center)**2)\n",
    "            \n",
    "            # Check if the neighbor is within the search radius\n",
    "            if distance <= search_radius:\n",
    "                num_neighbors += 1\n",
    "    \n",
    "    return num_neighbors\n",
    "\n",
    "# Calculate the number of neighbors for each row and add the results as a new column\n",
    "df['num_neighbors'] = df.apply(lambda row: count_neighbors(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOTAL NUMBER OF BIRDS PER IMAGE\n",
    "df['density'] = df.groupby('filename')['consensus_bbox'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISTANCE OF TARGET FROM IMAGE CENTER-- in meters\n",
    "\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\crowdsourced_gsd.csv\"\n",
    "with open(path1) as f1:\n",
    "  gsd_df = pd.read_csv(f1)\n",
    "\n",
    "gsd_df[\"basefile\"] = gsd_df[\"filename\"].apply(lambda x: os.path.splitext(x)[0])\n",
    "\n",
    "merged_df = pd.merge(df, gsd_df, on=\"basefile\", how=\"left\")\n",
    "merged_df = merged_df.rename(columns={\"filename_x\": \"filename\"})\n",
    "merged_df = merged_df.drop(columns=[\"filename_y\", \"filename_base\"])\n",
    "\n",
    "# Function to calculate distance from center\n",
    "def calculate_distance_from_center(row):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\zooniverse\", row[\"filename\"])\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None  # You can return a special value, such as None, to indicate the image wasn't found\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    center_x_px = image_width/2 \n",
    "    center_y_px = image_height/2\n",
    "    gsd_m = row['gsd'] / 100\n",
    "\n",
    "    row['center_x_m'] = center_x_px * gsd_m\n",
    "    row['center_y_m'] = center_y_px * gsd_m\n",
    "    \n",
    "    # Get the coordinates of the bounding box (x, y, width, height)\n",
    "    x, y, width, height = row['consensus_bbox']\n",
    "\n",
    "    # Calculate the center point of the bounding box in pixels\n",
    "    bbox_center_x_px = x + (width / 2)\n",
    "    bbox_center_y_px = y + (height / 2)\n",
    "\n",
    "    # Calculate the center point of the bounding box in meters\n",
    "    bbox_center_x_m = bbox_center_x_px * gsd_m\n",
    "    bbox_center_y_m = bbox_center_y_px * gsd_m\n",
    "\n",
    "    # Calculate the distance from the center of the image in meters\n",
    "    distance_m = ((row['center_x_m'] - bbox_center_x_m)**2 + (row['center_y_m'] - bbox_center_y_m)**2)**0.5\n",
    "\n",
    "    return distance_m\n",
    "\n",
    "# Apply the function to the merged dataframe\n",
    "merged_df['distance_from_center'] = merged_df.apply(calculate_distance_from_center, axis=1)\n",
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXTURE METRICS- GLCM\n",
    "#Bounding box and \"donut\" (buffer region directly around bbox)\n",
    "\n",
    "def calculate_glcm_derivatives(image, bbox):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width]\n",
    "    \n",
    "    # Check if the ROI is empty or None\n",
    "    if roi is None or roi.size == 0:\n",
    "        print(\"Warning: ROI is empty or None\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert the ROI to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate GLCM features for the grayscale ROI\n",
    "    distances = [1, 2]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi_gray, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GLCM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "def adjust_bbox_to_image(image, bbox):\n",
    "    # Get image dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # Adjust bounding box coordinates if they exceed image boundaries\n",
    "    x, y, width, height = bbox\n",
    "    \n",
    "    # Ensure the bounding box does not go beyond the image boundaries\n",
    "    x = max(x, 0)\n",
    "    y = max(y, 0)\n",
    "    width = min(width, image_width - x)\n",
    "    height = min(height, image_height - y)\n",
    "    \n",
    "    return x, y, width, height\n",
    "\n",
    "def calculate_texture_metrics_for_directory(image_dir, csv_file):\n",
    "    # Initialize an empty dataframe to store the texture metrics\n",
    "    texture_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    # List all files in the specified directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            \n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Image '{image_path}' not found or cannot be loaded.\")\n",
    "                continue\n",
    "            \n",
    "            # Read the CSV file\n",
    "            csv_data = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Find the corresponding image filename\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            \n",
    "            # Filter annotations based on the image filename\n",
    "            annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "            \n",
    "            # Initialize lists to store the texture metrics\n",
    "            bbox_contrast_list = []\n",
    "            bbox_dissimilarity_list = []\n",
    "            bbox_homogeneity_list = []\n",
    "            bbox_energy_list = []\n",
    "            donut_contrast_list = []\n",
    "            donut_dissimilarity_list = []\n",
    "            donut_homogeneity_list = []\n",
    "            donut_energy_list = []\n",
    "            \n",
    "            # Iterate through annotations and calculate texture metrics\n",
    "            for _, row in annotations.iterrows():\n",
    "                bbox = ast.literal_eval(row['consensus_bbox'])  # Parse bbox values from string to list\n",
    "                \n",
    "                # Adjust bounding box to stay within image boundaries\n",
    "                bbox = adjust_bbox_to_image(image, bbox)\n",
    "                \n",
    "                # Calculate GCLM derivatives for bounding box\n",
    "                bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_glcm_derivatives(image, bbox)\n",
    "                \n",
    "                donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "                donut_top = max(0, bbox[1] - 20)\n",
    "                donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "                donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "                donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "                donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_glcm_derivatives(image, donut_bbox)\n",
    "\n",
    "                # Append the calculated texture metrics to the lists\n",
    "                bbox_contrast_list.append(bbox_contrast)\n",
    "                bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "                bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "                bbox_energy_list.append(bbox_energy)\n",
    "                donut_contrast_list.append(donut_contrast)\n",
    "                donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "                donut_homogeneity_list.append(donut_homogeneity)\n",
    "                donut_energy_list.append(donut_energy)\n",
    "            \n",
    "            # Add texture metrics as columns to a temporary dataframe\n",
    "            temp_df = pd.DataFrame({\n",
    "                'ID': annotations[\"id\"],\n",
    "                'filename': [image_filename] * len(annotations),\n",
    "                'bbox_contrast': bbox_contrast_list,\n",
    "                'bbox_dissimilarity': bbox_dissimilarity_list,\n",
    "                'bbox_homogeneity': bbox_homogeneity_list,\n",
    "                'bbox_energy': bbox_energy_list,\n",
    "                'donut_contrast': donut_contrast_list,\n",
    "                'donut_dissimilarity': donut_dissimilarity_list,\n",
    "                'donut_homogeneity': donut_homogeneity_list,\n",
    "                'donut_energy': donut_energy_list\n",
    "            })\n",
    "            \n",
    "            # Append the temporary dataframe to the main dataframe\n",
    "            texture = pd.concat([texture, temp_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_path}': {e}\")\n",
    "\n",
    "# Implementation\n",
    "image_dir = 'path/to/image/directory'\n",
    "csv_file = 'path/to/labels.csv'\n",
    "\n",
    "calculate_texture_metrics_for_directory(image_dir, csv_file)\n",
    "\n",
    "df = pd.merge(df, texture, on=[\"id\", \"filename\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate simple differences for each GCLM statistic between label and donut\n",
    "df['contrast_difference'] = df['donut_contrast'] - df['bbox_contrast']\n",
    "df['energy_difference'] = df['donut_energy'] - df['bbox_energy']\n",
    "df['homogeneity_difference'] = df['donut_homogeneity'] - df['bbox_homogeneity']\n",
    "df['dissimilarity_difference'] = df['donut_dissimilarity'] - df['bbox_dissimilarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELING IMPACT OF IMAGE FACTORS ON ANNOTATION AGREEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variables for class ID\n",
    "data = pd.get_dummies(df, columns=[\"consensus_class_ID\"], prefix=\"class\")\n",
    "for column in data.filter(like='class_'):\n",
    "    data[column] = data[column].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming 'data' is your DataFrame with predictor variables\n",
    "predictors = data[[\n",
    " 'bbox_percent_area',\n",
    " 'same_class_percent',\n",
    " 'num_neighbors',\n",
    " 'agl',\n",
    " 'gsd',\n",
    " 'distance_from_center',\n",
    " 'density',\n",
    " 'bbox_contrast',\n",
    " 'bbox_dissimilarity',\n",
    " 'bbox_homogeneity',\n",
    " 'bbox_energy',\n",
    " 'donut_contrast',\n",
    " 'donut_dissimilarity',\n",
    " 'donut_homogeneity',\n",
    " 'donut_energy',\n",
    " 'contrast_difference',\n",
    " 'energy_difference',\n",
    " 'homogeneity_difference',\n",
    " 'dissimilarity_difference',\n",
    " 'class_Crane',\n",
    " 'class_Duck',\n",
    " 'class_Goose',\n",
    " 'class_Other Bird']]\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = predictors.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])]\n",
    "\n",
    "# Display the VIF DataFrame\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple linear regression \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = data['n-k']\n",
    "X = data[['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density', 'contrast_difference', 'energy_difference', 'homogeneity_difference', 'dissimilarity_difference',\n",
    "        'class_Crane', 'class_Duck', 'class_Goose']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
